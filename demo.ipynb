{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fractal Embeddings Demo Notebook\n",
    "\n",
    "This walks through some of the functionality contained in this repo with example results.\n",
    "\n",
    "#### Main Point of This File\n",
    "- To describe code functionality \n",
    "- To steal code snippets and shell commands\n",
    "- A playground for development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Embeddings from Text Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `embed_text_cohere.py` script takes a directory containing text files and generates embeddings using Cohere's API. The embeddings are saved as a DataFrame in a `.csv` file. This script supports recursive search for `.md` files in the input directory and can handle API rate limits.\n",
    "\n",
    "Here's an example of how to run the script from the command line:\n",
    "\n",
    "```bash\n",
    "python src/embed_text_cohere.py -i ./data -e output_embeddings.csv -c config.ini\n",
    "```\n",
    "\n",
    "Review the script to understand the command line arguments. Briefly, the -i input dir is being stored in the -e embedding file and a -n npz file, with an api key found in -c config.ini\n",
    "\n",
    "Now let's run the script using the provided data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:11<00:00,  1.88s/it]\n",
      "Embedding text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:14<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "!python src/embed_text_cohere.py -i ./data/memory -e ./demo_data/memory_embeddings.csv -n -c config.ini\n",
    "!python src/embed_text_cohere.py -i ./data/my-second-brain -e ./demo_data/my_second_brain_embeddings.csv -n -c config.ini"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above commands, you should have two `.csv` files containing embeddings for your data: `memory_embeddings.csv`and `my_second_brain_embeddings.csv`. You can load these files using pandas and visualize the embeddings or perform further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>index</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heretics of Dune</td>\n",
       "      <td>0</td>\n",
       "      <td># Heretics of Dune ![rw-book-cover](https://im...</td>\n",
       "      <td>[1.4345703, -0.37695312, 0.18273926, -0.636718...</td>\n",
       "      <td>['Frank Herbert', 'Books', 'Psychedelics', 'Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSC 581</td>\n",
       "      <td>1</td>\n",
       "      <td>--- **Status::** #üó∫Ô∏è **Tags::** [[MOC]], [[Win...</td>\n",
       "      <td>[0.92285156, -0.5053711, 0.7392578, 0.30615234...</td>\n",
       "      <td>['MOC', 'Winter 2023']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tensorflow Mac M1</td>\n",
       "      <td>2</td>\n",
       "      <td>## AAAh [Good post on SO](https://stackoverflo...</td>\n",
       "      <td>[1.8417969, 0.6347656, 0.027954102, 1.9462891,...</td>\n",
       "      <td>['Programming Notes']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tensorflow Mac M1</td>\n",
       "      <td>2</td>\n",
       "      <td>optimizer=tf.keras.optimizers.legacy.Adam(lear...</td>\n",
       "      <td>[3.5527344, 0.11090088, 0.33618164, 1.2988281,...</td>\n",
       "      <td>['Programming Notes']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snowflake</td>\n",
       "      <td>3</td>\n",
       "      <td>## Snowflake Here's to you - You doubters of m...</td>\n",
       "      <td>[0.80810547, 1.3378906, -0.18164062, 0.0483093...</td>\n",
       "      <td>['Poetry', 'My Writings']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  index  \\\n",
       "0   Heretics of Dune      0   \n",
       "1            CSC 581      1   \n",
       "2  Tensorflow Mac M1      2   \n",
       "3  Tensorflow Mac M1      2   \n",
       "4          Snowflake      3   \n",
       "\n",
       "                                          chunk_text  \\\n",
       "0  # Heretics of Dune ![rw-book-cover](https://im...   \n",
       "1  --- **Status::** #üó∫Ô∏è **Tags::** [[MOC]], [[Win...   \n",
       "2  ## AAAh [Good post on SO](https://stackoverflo...   \n",
       "3  optimizer=tf.keras.optimizers.legacy.Adam(lear...   \n",
       "4  ## Snowflake Here's to you - You doubters of m...   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [1.4345703, -0.37695312, 0.18273926, -0.636718...   \n",
       "1  [0.92285156, -0.5053711, 0.7392578, 0.30615234...   \n",
       "2  [1.8417969, 0.6347656, 0.027954102, 1.9462891,...   \n",
       "3  [3.5527344, 0.11090088, 0.33618164, 1.2988281,...   \n",
       "4  [0.80810547, 1.3378906, -0.18164062, 0.0483093...   \n",
       "\n",
       "                                               links  \n",
       "0  ['Frank Herbert', 'Books', 'Psychedelics', 'Sc...  \n",
       "1                             ['MOC', 'Winter 2023']  \n",
       "2                              ['Programming Notes']  \n",
       "3                              ['Programming Notes']  \n",
       "4                          ['Poetry', 'My Writings']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "memory_embeddings_df = pd.read_csv('./demo_data/memory_embeddings.csv')\n",
    "my_second_brain_embeddings_df = pd.read_csv('./demo_data/my_second_brain_embeddings.csv')\n",
    "\n",
    "memory_embeddings_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>index</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome in my mind üß†</td>\n",
       "      <td>0</td>\n",
       "      <td>## Who I am? I'm **Anthony**, a `Date.today.ye...</td>\n",
       "      <td>[0.8691406, -0.91748047, 1.21875, -1.6054688, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome in my mind üß†</td>\n",
       "      <td>0</td>\n",
       "      <td>want. Here's a hint: you can just watch the su...</td>\n",
       "      <td>[0.75634766, -0.33984375, 0.22790527, -1.01953...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>README</td>\n",
       "      <td>1</td>\n",
       "      <td>*You'll have a better browsing experience of t...</td>\n",
       "      <td>[1.0322266, -1.8320312, 0.36694336, -0.9697265...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>README</td>\n",
       "      <td>1</td>\n",
       "      <td>deep into a wide variety of fields and engage ...</td>\n",
       "      <td>[1.2236328, -0.5444336, -0.43579102, 0.4089355...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contact me üíå</td>\n",
       "      <td>2</td>\n",
       "      <td>## Want to get in touch? üòä I'd love to hear fr...</td>\n",
       "      <td>[-0.6777344, 0.38598633, 1.8916016, -2.1796875...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  index  \\\n",
       "0  Welcome in my mind üß†      0   \n",
       "1  Welcome in my mind üß†      0   \n",
       "2                README      1   \n",
       "3                README      1   \n",
       "4          Contact me üíå      2   \n",
       "\n",
       "                                          chunk_text  \\\n",
       "0  ## Who I am? I'm **Anthony**, a `Date.today.ye...   \n",
       "1  want. Here's a hint: you can just watch the su...   \n",
       "2  *You'll have a better browsing experience of t...   \n",
       "3  deep into a wide variety of fields and engage ...   \n",
       "4  ## Want to get in touch? üòä I'd love to hear fr...   \n",
       "\n",
       "                                           embedding links  \n",
       "0  [0.8691406, -0.91748047, 1.21875, -1.6054688, ...    []  \n",
       "1  [0.75634766, -0.33984375, 0.22790527, -1.01953...    []  \n",
       "2  [1.0322266, -1.8320312, 0.36694336, -0.9697265...    []  \n",
       "3  [1.2236328, -0.5444336, -0.43579102, 0.4089355...    []  \n",
       "4  [-0.6777344, 0.38598633, 1.8916016, -2.1796875...    []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_second_brain_embeddings_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll perform dimensionality reduction on the embeddings to visualize them in a lower-dimensional space. The `dimensionality_reduction.py` script can perform PCA, t-SNE, and UMAP dimensionality reduction methods. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Embeddings\n",
    "\n",
    "Before performing dimensionality reduction, let's combine the two sets of embeddings into a single file. We'll use numpy to load, concatenate, and save the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "memory_embeddings = np.load('./demo_data/memory_embeddings.npz', allow_pickle=True)\n",
    "my_second_brain_embeddings = np.load('./demo_data/my_second_brain_embeddings.npz', allow_pickle=True)\n",
    "\n",
    "combined_embeddings = np.concatenate((memory_embeddings['embeddings'], my_second_brain_embeddings['embeddings']), axis=0)\n",
    "combined_filenames = np.concatenate((memory_embeddings['filenames'], my_second_brain_embeddings['filenames']), axis=0)\n",
    "np.savez('./demo_data/combined_embeddings.npz', filenames=combined_filenames, embeddings=combined_embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Dimensionality Reduction\n",
    "Now we'll run the dimensionality_reduction.py script on the combined embeddings. This script supports PCA, t-SNE, and UMAP reduction methods. You can specify which methods to use with the `-r` argument. By default, it will run all methods.\n",
    "\n",
    "Rundown of the following command:\n",
    "\n",
    "Reduce the -e embeddings npz, -o output the results to npz, and -p plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCA 5\n",
      "Running t-SNE 2\n",
      "Running UMAP 5\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "Running UMAP 2\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!python src/dimensionality_reduction.py -e demo_data/combined_embeddings.npz -o demo_data/combined_reduced_embeddings.npz -p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above command, you should have an NPZ file `demo_data/combined_reduced_embeddings.npz` containing reduced embeddings for the combined dataset. You can load this file using numpy and visualize the embeddings or perform further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_embeddings = np.load('demo_data/combined_reduced_embeddings.npz')\n",
    "\n",
    "# Example of accessing the reduced embeddings\n",
    "pca5_embeddings = reduced_embeddings['pca5']\n",
    "tsne2_embeddings = reduced_embeddings['tsne2']\n",
    "umap5_embeddings = reduced_embeddings['umap5']\n",
    "umap2_embeddings = reduced_embeddings['umap2']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# TreeNode class definition\n",
    "class TreeNode:\n",
    "    def __init__(self, left=None, right=None, filenames=None, data=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.filenames = filenames\n",
    "        self.data = data\n",
    "\n",
    "# Load the tree\n",
    "def load_tree(input_file):\n",
    "    with open(input_file, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "tree = load_tree('../demo_data/combined_dendrogram.pkl')\n",
    "\n",
    "# Load the data\n",
    "embedding_npz = np.load('../demo_data/combined_reduced_embeddings.npz')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
